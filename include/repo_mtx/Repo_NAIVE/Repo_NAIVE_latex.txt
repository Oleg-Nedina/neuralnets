\documentclass[aspectratio=169, 11pt]{beamer}

% --- AESTHETIC SETUP ---
\usetheme{Madrid}
\usecolortheme{seahorse} 
\usefonttheme{structurebold} 
\setbeamertemplate{footline}{}
\setbeamertemplate{navigation symbols}{}

\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{colortbl} % Per evidenziare celle se necessario

% Metadata
\title{Scalability Analysis: Naive Implementation}
\subtitle{Precision Impact \& Benchmark vs OpenBLAS}
\author{Project AMSC}
\date{\today}

\begin{document}

% --- TITLE SLIDE ---
\begin{frame}
    \titlepage
\end{frame}

% --- SLIDE 1: VISUAL COMPARISON ---
\begin{frame}{Performance Overview: Naive (Float)}
    \begin{columns}[T]
        % LEFT: Time Plot
        \begin{column}{0.48\textwidth}
            \centering
            \includegraphics[width=\textwidth, height=0.55\textheight, keepaspectratio]{time_naive_float.png}
            \captionof{figure}{\textbf{Execution Time (ms)}}
            \small{\textit{Exponential growth due to cache thrashing.}}
        \end{column}
        
        % RIGHT: GFLOPS Plot
        \begin{column}{0.48\textwidth}
            \centering
            \includegraphics[width=\textwidth, height=0.55\textheight, keepaspectratio]{gflops_naive_float.png}
            \captionof{figure}{\textbf{Throughput (GFLOPS)}}
            \small{\textit{Performance remains < 2 GFLOPS regardless of size.}}
        \end{column}
    \end{columns}
\end{frame}

% --- SLIDE 2: FLOAT VS DOUBLE COMPARISON ---
\begin{frame}{Quantitative Analysis: Float vs Double}
    \begin{columns}
        % LEFT: Benchmark Table
        \begin{column}{0.55\textwidth}
            \centering
            \textbf{Impact of Precision on Execution Time}
            \vspace{0.2cm}
            
            \renewcommand{\arraystretch}{1.3}
            \small
            \begin{tabular}{l r r r}
                \toprule
                \textbf{Size ($N$)} & \textbf{Float} & \textbf{Double} & \textbf{$\Delta$ Overhead} \\
                \midrule
                $128^3$ & 2.59 ms & 3.85 ms & \textcolor{orange}{+48\%} \\
                $512^3$ & 278 ms & 377 ms & \textcolor{orange}{+35\%} \\
                $1024^3$ & 3.63 s & 5.22 s & \textcolor{orange}{+43\%} \\
                $2048^3$ & \alert{47.60 s} & \alert{48.94 s} & \textcolor{blue}{\textbf{Only +2.8\%}} \\
                \bottomrule
            \end{tabular}
        \end{column}

        % RIGHT: Analysis Text
        \begin{column}{0.42\textwidth}
             \begin{block}{Insight: The "Latency Wall"}
                \small
                For smaller sizes, \texttt{double} is slower due to higher bandwidth usage (8 bytes vs 4 bytes).
                \vspace{0.2cm}
                
                However, at \textbf{N=2048}, the difference disappears.
                \vspace{0.1cm}
                
                \textbf{Why?} The CPU is entirely stalled by \textit{latency} (waiting for RAM), not \textit{bandwidth} (transfer speed). The penalty for jumping around in memory masks the data size difference.
            \end{block}
        \end{column}
    \end{columns}
    
    \vspace{0.4cm}
    \centering
    \footnotesize Reference: OpenBLAS (Float) at $N=2048$ takes only \textbf{0.058 s} ($\approx 820$x faster).
\end{frame}

% --- SLIDE 3: TECHNICAL DIAGNOSIS ---
\begin{frame}{Why does Naive fail? (Bottleneck Analysis)}
    \begin{columns}
        \begin{column}{0.6\textwidth}
            The standard ($ijk$) implementation exposes critical hardware limitations:
            
            \vspace{0.3cm}
            \begin{itemize}
                \setlength\itemsep{1em}
                \item \textbf{Cache Thrashing (Major):} 
                Matrix $B$ is accessed column-wise ($stride = N$). This breaks spatial locality, causing a massive amount of L1/L2 cache misses.
                
                \item \textbf{Precision Penalty:} 
                Using \texttt{double} halves the effective SIMD width (2 doubles vs 4 floats per 128-bit vector) and consumes 2x cache lines, exacerbating the cache pressure.
                
                \item \textbf{Pipeline Stalls:} 
                The CPU spends most cycles waiting for data fetch rather than computing.
            \end{itemize}
        \end{column}
        
        \begin{column}{0.35\textwidth}
            \centering
            \setbeamercolor{block body}{bg=red!10,fg=black}
            \begin{block}{Memory Access Pattern}
                \centering
                \texttt{B[k][j]} with varying \texttt{k}
                \vspace{0.2cm}
                
                \includegraphics[width=0.6\textwidth, keepaspectratio]{example-image-a} % Placeholder visual
                
                \scriptsize{Jumping $N \times 4$ bytes every step leads to RAM fetch instead of Cache hit.}
            \end{block}
        \end{column}
    \end{columns}
\end{frame}

\end{document}