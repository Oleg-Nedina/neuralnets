\documentclass[aspectratio=169, 11pt]{beamer}

% --- SETUP ESTETICO ---
\usetheme{Madrid}
\usecolortheme{seahorse}
\usefonttheme{structurebold}

% Rimuovi elementi di disturbo per layout pulito
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}{}

% Pacchetti
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{caption}

% Metadati
\title{Scalability Analysis: Loop Unrolling}
\subtitle{Instruction Level Optimization vs Memory Wall}
\author{Progetto AMSC}
\date{\today}

\begin{document}

% --- TITOLO ---
\begin{frame}
    \titlepage
\end{frame}

% --- SLIDE 1: CONFRONTO VISIVO ---
\begin{frame}{Performance Overview: Loop Unrolling (Float)}
    \begin{columns}[T]
        % Grafico Tempo
        \begin{column}{0.48\textwidth}
            \centering
            \includegraphics[width=\textwidth, height=0.55\textheight, keepaspectratio]{time_unroll_float.png}
            \captionof{figure}{\textbf{Execution Time (ms)}}
            \small{\textit{Curve remains cubic ($O(N^3)$). No visible improvement over Naive.}}
        \end{column}

        % Grafico GFLOPS
        \begin{column}{0.48\textwidth}
            \centering
            \includegraphics[width=\textwidth, height=0.55\textheight, keepaspectratio]{gflops_unroll_float.png}
            \captionof{figure}{\textbf{Throughput (GFLOPS)}}
            \small{\textit{Throughput is negligible ($< 1$ GFLOP), constrained by latency.}}
        \end{column}
    \end{columns}
\end{frame}

% --- SLIDE 2: CONFRONTO FLOAT VS DOUBLE ---
\begin{frame}{Quantitative Analysis: Float vs Double}
    \begin{columns}
        % Tabella
        \begin{column}{0.55\textwidth}
            \centering
            \textbf{Impact of Unrolling on Execution Time}
            \vspace{0.2cm}

            \renewcommand{\arraystretch}{1.3}
            \small
            \begin{tabular}{l r r r}
                \toprule
                \textbf{Size ($N$)} & \textbf{Float} & \textbf{Double} & \textbf{vs Naive (Float)} \\
                \midrule
                $128^3$ & 2.15 ms & 3.42 ms & \textcolor{green!50!black}{-16\% (Faster)} \\
                $1024^3$ & 4.79 s & 4.31 s & \textcolor{red}{+31\% (Slower)} \\
                $1536^3$ & \alert{13.44 s} & \alert{19.02 s} & \textcolor{red}{High Instability} \\
                $2048^3$ & 49.68 s & 53.70 s & \textcolor{red}{\textbf{+4\% (Slower)}} \\
                \bottomrule
            \end{tabular}
        \end{column}

        % Analisi Testuale
        \begin{column}{0.42\textwidth}
             \begin{block}{The "Optimization Theatre"}
                Loop Unrolling aims to reduce loop overhead (incrementing counters, branching).

                \vspace{0.2cm}
                \textbf{Result:} It failed to improve performance. At $N=2048$, it is essentially identical to (or slightly slower than) the Naive implementation.

                \vspace{0.2cm}
                \textbf{Reason:} Saving a few CPU cycles on loop control is irrelevant when the CPU is stalled for hundreds of cycles waiting for Memory (Cache Misses).
            \end{block}
        \end{column}
    \end{columns}
\end{frame}

% --- SLIDE 3: DIAGNOSI TECNICA ---
\begin{frame}{Why did Unrolling fail?}
    \begin{columns}
        \begin{column}{0.6\textwidth}
            Manually unrolling the loop (processing 4 or 8 elements explicitly) changes the instruction stream but not the data access pattern.

            \vspace{0.3cm}
            \begin{itemize}
                \setlength\itemsep{1em}
                \item \textbf{Same Memory Access Pattern:}
                We are still accessing matrix $B$ by columns ($stride = N$). The L1 Cache Miss rate remains near 100\% for large $N$.

                \item \textbf{Compiler Optimization:}
                Modern compilers (GCC/Clang) at \texttt{-O2} or \texttt{-O3} often auto-unroll loops better than manual attempts. Manual unrolling might confuse the compiler's heuristic.

                \item \textbf{Instruction Cache Pressure:}
                Unrolling increases the binary code size, potentially causing Instruction Cache misses.
            \end{itemize}
        \end{column}

        \begin{column}{0.35\textwidth}
            \centering
            \setbeamercolor{block body}{bg=yellow!10,fg=black}
            \begin{block}{Visual Concept}
                \scriptsize
                \textbf{Loop Control (Saved):}\\
                \texttt{i++}, \texttt{if i < N jump}\\
                (Cost: $\approx 1-2$ cycles)
                \vspace{0.2cm}

                \textbf{Memory Fetch (Unchanged):}\\
                \texttt{Load B[k][j]}\\
                (Cost: $\approx 100-300$ cycles)
                \vspace{0.2cm}

                \textbf{Conclusion:} The bottleneck is the Fetch, not the Loop Control.
            \end{block}
        \end{column}
    \end{columns}
\end{frame}

\end{document}